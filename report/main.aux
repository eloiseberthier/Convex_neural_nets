\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand*\new@tpo@label[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\babel@aux{english}{}
\citation{zhang2016convexified}
\citation{haeffele2017global}
\citation{visualloss}
\citation{du2018agradient}
\citation{du2018bgradient}
\citation{zou2018stochastic}
\citation{jacot2018neural}
\citation{chizat:hal-01945578}
\citation{bengio2006convex}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}{section.1}}
\citation{bach2017breaking}
\citation{chizat2018global}
\@writefile{toc}{\contentsline {section}{\numberline {2}Towards a Convex Problem}{3}{section.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}General layout}{3}{subsection.2.1}}
\citation{bengio2006convex}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}From non-convexity to convexity}{4}{subsection.2.2}}
\citation{bach2017breaking}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Variation norm}{5}{subsection.2.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Problem formulation in $\mathcal  {F}_1$}{6}{subsection.2.4}}
\citation{le2007continuous}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Problem formulation in $\mathcal  {F}_2$}{7}{subsection.2.5}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Theoretical Analysis}{8}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Adaptivity to structure}{8}{subsection.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Error decomposition}{8}{subsection.3.2}}
\citation{bach2017breaking}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Generalization properties}{9}{subsection.3.3}}
\citation{bach2017breaking}
\@writefile{toc}{\contentsline {section}{\numberline {4}An Optimization Problem}{10}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}The conditional gradient algorithm}{10}{subsection.4.1}}
\citation{bach2017breaking}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}The problem with Frank-Wolfe}{11}{subsection.4.2}}
\citation{chizat2018global}
\citation{chizat2018global}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}An approach using particle gradient flow}{12}{subsection.4.3}}
\citation{chizat2018global}
\@writefile{toc}{\contentsline {section}{\numberline {5}Numerical Experiments}{13}{section.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Particle gradient flow in dimension 2}{13}{subsection.5.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:sub3}{{1a}{14}{Convergence to the global minimum\relax }{figure.caption.2}{}}
\newlabel{sub@fig:sub3}{{a}{14}{Convergence to the global minimum\relax }{figure.caption.2}{}}
\newlabel{fig:sub4}{{1b}{14}{Convergence to a local minimum\relax }{figure.caption.2}{}}
\newlabel{sub@fig:sub4}{{b}{14}{Convergence to a local minimum\relax }{figure.caption.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Trajectories of weights during training in two different experiments with ReLU\relax }}{14}{figure.caption.2}}
\newlabel{fig:sub3}{{2a}{14}{Convergence with 50 particles\relax }{figure.caption.3}{}}
\newlabel{sub@fig:sub3}{{a}{14}{Convergence with 50 particles\relax }{figure.caption.3}{}}
\newlabel{fig:sub4}{{2b}{14}{Convergence with 10 particles\relax }{figure.caption.3}{}}
\newlabel{sub@fig:sub4}{{b}{14}{Convergence with 10 particles\relax }{figure.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Trajectories of weights during training with sigmoid\relax }}{14}{figure.caption.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}How much over-parametrization is needed?}{15}{subsection.5.2}}
\citation{chizat2018global}
\newlabel{fig:sub3}{{3a}{16}{Convergence to zero loss with 20 particles\relax }{figure.caption.5}{}}
\newlabel{sub@fig:sub3}{{a}{16}{Convergence to zero loss with 20 particles\relax }{figure.caption.5}{}}
\newlabel{fig:sub4}{{3b}{16}{Convergence to non zero loss with 5 particles\relax }{figure.caption.5}{}}
\newlabel{sub@fig:sub4}{{b}{16}{Convergence to non zero loss with 5 particles\relax }{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Training with ReLU in over-parametrization and under-parametrization regimes\relax }}{16}{figure.caption.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Excess loss at convergence for an increasing number of particles with ReLU\relax }}{17}{figure.caption.6}}
\newlabel{fig:3}{{4}{17}{Excess loss at convergence for an increasing number of particles with ReLU\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Excess loss at convergence for an increasing number of particles with sigmoid\relax }}{17}{figure.caption.7}}
\newlabel{fig:3}{{5}{17}{Excess loss at convergence for an increasing number of particles with sigmoid\relax }{figure.caption.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Lazy or active training?}{17}{subsection.5.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Influence of $r_0$ through training with $k=20$ particles\relax }}{18}{figure.caption.8}}
\newlabel{fig:3}{{6}{18}{Influence of $r_0$ through training with $k=20$ particles\relax }{figure.caption.8}{}}
\newlabel{fig:sub3}{{7a}{18}{Weights trajectory for $r_0=0.05$\relax }{figure.caption.9}{}}
\newlabel{sub@fig:sub3}{{a}{18}{Weights trajectory for $r_0=0.05$\relax }{figure.caption.9}{}}
\newlabel{fig:sub4}{{7b}{18}{Weights trajectory for $r_0=10$\relax }{figure.caption.9}{}}
\newlabel{sub@fig:sub4}{{b}{18}{Weights trajectory for $r_0=10$\relax }{figure.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Two different behaviours in the trajectories of weights with ReLU\relax }}{18}{figure.caption.9}}
\citation{chizat:hal-01945578}
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusion}{19}{section.6}}
\bibstyle{apalike}
\bibdata{biblio.bib}
\bibcite{video}{Bach, 2016}
\bibcite{bach2017breaking}{Bach, 2017}
\bibcite{bengio2006convex}{Bengio et~al., 2006}
\bibcite{chizat:hal-01945578}{Chizat and Bach, 2018a}
\bibcite{chizat2018global}{Chizat and Bach, 2018b}
\bibcite{du2018bgradient}{Du et~al., 2018a}
\bibcite{du2018agradient}{Du et~al., 2018b}
\bibcite{haeffele2017global}{Haeffele and Vidal, 2017}
\bibcite{jacot2018neural}{Jacot et~al., 2018}
\bibcite{le2007continuous}{Le~Roux and Bengio, 2007}
\bibcite{visualloss}{Li et~al., 2018}
\bibcite{zhang2016convexified}{Zhang et~al., 2016}
\bibcite{zou2018stochastic}{Zou et~al., 2018}
\citation{video}
